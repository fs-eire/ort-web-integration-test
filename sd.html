<html>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.1/dist/css/bootstrap.min.css" rel="stylesheet"
    integrity="sha384-4bw+/aepP/YC94hEpVNVgiZdgIC5+VKNBQNGCHeKRQN+PtmoHDEXuppvnDJzQIu9" crossorigin="anonymous" />
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.1/dist/js/bootstrap.bundle.min.js"
    integrity="sha384-HwwvtgBNo3bZJJLYd8oVXjrBZt8cqVSpeBNS5n7C8IVInixGAoxmnlMuBnhbgrkm" crossorigin="anonymous">
    </script>

<head>
    <title>Stable Diffusion Turbo</title>
</head>

<style>
    .onerow {
        display: flex;
    }
</style>

<body data-bs-theme="dark">
    <div class="container">
        <div class="row pt-3">
            <div class="col-md-9 col-12">
                <h2>Stable Diffusion Turbo</h2>
            </div>
        </div>
        <div class="container p-2 card" id="input-area">
            <div class="input-group">
                <textarea class="form-control" id="user-input" placeholder="Type your question here..."></textarea>
                <button id="send-button" class="btn btn-primary">Send</button>
            </div>
        </div>
        <div id="image_area">
            <div class="onerow">
                <div id="img_div_0" style="margin-right: 4px;">
                    <canvas id="img_canvas_0"></canvas>
                </div>
                <div id="img_div_1" style="margin-right: 4px;">
                    <canvas id="img_canvas_1"></canvas>
                </div>
                <div id="img_div_2" style="margin-right: 4px;">
                    <canvas id="img_canvas_2"></canvas>
                </div>
                <div id="img_div_3" style="margin-right: 4px;">
                    <canvas id="img_canvas_3"></canvas>
                </div>
            </div>
        </div>
        <p class="text-lg-start">
        <div id="status" style="font: 1em consolas;"></div>
        </p>
    </div>
</body>

<script type="module">
    function log(i) { console.log(i); document.getElementById('status').innerText += `\n${i}`; }

    function getConfig() {
        const query = window.location.search.substring(1);
        var config = {
            // model: "models/onnx-sd-turbo-fp16",
            model: "https://huggingface.co/schmuell/sd-turbo-ort-web/resolve/main",
            provider: "webgpu",
            device: "gpu",
            threads: "1",
            images: "2",
            ort: "",
        };
        let vars = query.split("&");
        for (var i = 0; i < vars.length; i++) {
            let pair = vars[i].split("=");
            if (pair[0] in config) {
                config[pair[0]] = decodeURIComponent(pair[1]);
            } else if (pair[0].length > 0) {
                throw new Error("unknown argument: " + pair[0]);
            }
        }
        config.threads = parseInt(config.threads);
        config.images = parseInt(config.images);
        return config;
    }

    function randn_latents(shape, noise_sigma) {
        function randn() {
            // Use the Box-Muller transform
            let u = Math.random();
            let v = Math.random();
            let z = Math.sqrt(-2 * Math.log(u)) * Math.cos(2 * Math.PI * v);
            return z;
        }
        let size = 1;
        shape.forEach(element => {
            size *= element;
        });

        let data = new Float32Array(size);
        // Loop over the shape dimensions
        for (let i = 0; i < size; i++) {
            data[i] = randn() * noise_sigma;
        }
        return data;
    }

    async function fetchAndCache(base_url, model_path) {
        const url = `${base_url}/${model_path}`;
        try {
            const cache = await caches.open("onnx");
            let cachedResponse = await cache.match(url);
            if (cachedResponse == undefined) {
                await cache.add(url);
                cachedResponse = await cache.match(url);
                log(`${model_path} (network)`);
            } else {
                log(`${model_path} (cached)`);
            }
            const data = await cachedResponse.arrayBuffer();
            return data;
        } catch (error) {
            log(`${model_path} (network)`);
            return await fetch(url).then(response => response.arrayBuffer());
        }
    }

    async function load_models(models) {
        const cache = await caches.open("onnx");
        let missing = 0;
        for (const [name, model] of Object.entries(models)) {
            const url = `${config.model}/${model.url}`;
            let cachedResponse = await cache.match(url);
            if (cachedResponse === undefined) {
                missing += model.size;
            }
        }
        if (missing > 0) {
            log(`downloading ${missing} MB from network ... it might take a while`);
        } else {
            log("loading...");
        }
        for (const [name, model] of Object.entries(models)) {
            try {
                const start = performance.now();
                const model_bytes = await fetchAndCache(config.model, model.url);
                const sess_opt = { ...opt, ...model.opt };
                models[name].sess = await ort.InferenceSession.create(model_bytes, sess_opt);
                const stop = performance.now();
                log(`${model.url} in ${(stop - start).toFixed(1)}ms`);
            } catch (e) {
                log(`${model.url} failed, ${e}`);
            }
        }
        log("ready.");
    }

    const urlParams = new URLSearchParams(window.location.search);
    const ort_param = urlParams.get("ort");
    const ort_import_param = urlParams.get("ort_import");

        let ort, AutoTokenizer, env;
        if (ort_param == "1") {
            const url = `${ort_import_param ?? './ort-dist/'}ort.mjs`;
            log(`importing from local JSEP: ${url}`);
            ort = await import(url);
            ({ AutoTokenizer, env } = await import("https://cdn.jsdelivr.net/npm/@xenova/transformers/dist/transformers.js"));
        } else if (ort_param == "2") {
            const url = `${ort_import_param ?? './ort-dist/'}ort.webgpu.mjs`;
            log(`importing from local WebGPUEP: ${url}`);
            ort = await import(url);
            ({ AutoTokenizer, env } = await import("https://cdn.jsdelivr.net/npm/@xenova/transformers/dist/transformers.js"));
        } else if (ort_param == "3") {
            const url = `${ort_import_param ?? './ort-dist/'}ort.jspi.mjs`;
            log(`importing from local JSPI: ${url}`);
            ort = await import(url);
            ({ AutoTokenizer, env } = await import("https://cdn.jsdelivr.net/npm/@xenova/transformers/dist/transformers.js"));
        } else {
            log("importing from CDN");
            ort = await import('https://cdn.jsdelivr.net/npm/onnxruntime-web@1.23.0-dev.20250906-ecb26fb775/dist/ort.mjs');
            ({ AutoTokenizer, env } = await import("https://cdn.jsdelivr.net/npm/@xenova/transformers/dist/transformers.js"));
        }

    const config = getConfig();

    const models = {
        "unet": {
            url: "unet/model.onnx", size: 640,
            // should have 'steps: 1' but will fail to create the session
            opt: { freeDimensionOverrides: { batch_size: 1, num_channels: 4, height: 64, width: 64, sequence_length: 77, } }
        },
        "text_encoder": {
            url: "text_encoder/model.onnx", size: 1700,
            // should have 'sequence_length: 77' but produces a bad image
            opt: { freeDimensionOverrides: { batch_size: 1, } },
        },
        "vae_decoder": {
            url: "vae_decoder/model.onnx", size: 95,
            opt: { freeDimensionOverrides: { batch_size: 1, num_channels_latent: 4, height_latent: 64, width_latent: 64 } }
        }
    }

    const text = document.getElementById("user-input");

    let tokenizer;
    let loading;
    const sigma = 14.6146;
    const gamma = 0;
    const vae_scaling_factor = 0.18215;

    // text.value = "A cinematic shot of a baby racoon wearing an intricate italian priest robe.";
    text.value = "Paris with the river in the background";

    if (config.provider == "webgpu") {
        ort.env.wasm.numThreads = 1;
        ort.env.wasm.simd = true;
    } else {
        ort.env.wasm.numThreads = config.threads;
        ort.env.wasm.simd = true;
    }

    const opt = {
        executionProviders: [config.provider],
        enableMemPattern: false,
        enableCpuMemArena: false,
        extra: {
            session: {
                disable_prepacking: "1",
                use_device_allocator_for_initializers: "1",
                use_ort_model_bytes_directly: "1",
                use_ort_model_bytes_for_initializers: "1"
            }
        },
    };

    switch (config.provider) {
        case "webgpu":
            if (!("gpu" in navigator)) {
                throw new Error("webgpu is NOT supported");
            }
            opt.preferredOutputLocation = { last_hidden_state: "gpu-buffer" };
            break;
        case "webnn":
            if (!("ml" in navigator)) {
                throw new Error("webnn is NOT supported");
            }
            opt.executionProviders = [{
                name: "webnn",
                deviceType: config.device,
                powerPreference: 'default'
            }];
            break;
    }

    // Event listener for Ctrl + Enter or CMD + Enter
    document.getElementById('user-input').addEventListener('keydown', function (e) {
        if ((e.ctrlKey || e.metaKey) && e.key === 'Enter') {
            run();
        }
    });
    document.getElementById('send-button').addEventListener('click', function (e) {
        run()
    });

    function init_latents(t) {
        const d = t.data;
        for (let i = 0; i < d.length; i++) {
            d[i] = d[i] * sigma;
        }
        return t;
    }

    function scale_model_inputs(t) {
        const d_i = t.data;
        const d_o = new Float32Array(d_i.length);

        const divi = (sigma ** 2 + 1) ** 0.5;
        for (let i = 0; i < d_i.length; i++) {
            d_o[i] = d_i[i] / divi;
        }
        return new ort.Tensor(d_o, t.dims);
    }

    function step(model_output, sample) {
        // poor mens EulerA. 
        // Since this is just a example for sd-turbo, only implement the absolute minimum
        // needed to create an image
        const d_o = new Float32Array(model_output.data.length);
        const prev_sample = new ort.Tensor(d_o, model_output.dims);
        const sigma_hat = sigma * (gamma + 1);

        for (let i = 0; i < model_output.data.length; i++) {
            const pred_original_sample = sample.data[i] - sigma_hat * model_output.data[i];
            const derivative = (sample.data[i] - pred_original_sample) / sigma_hat;
            const dt = 0 - sigma_hat;
            d_o[i] = (sample.data[i] + derivative * dt) / vae_scaling_factor;
        }
        return prev_sample;
    }

    function draw_image(t, image_nr) {
        let pix = t.data;
        for (var i = 0; i < pix.length; i++) {
            let x = pix[i];
            x = x / 2 + 0.5
            if (x < 0.) x = 0.;
            if (x > 1.) x = 1.;
            pix[i] = x;
        }
        const imageData = t.toImageData({ tensorLayout: 'NCWH', format: 'RGB' });
        const canvas = document.getElementById(`img_canvas_${image_nr}`);
        canvas.width = imageData.width;
        canvas.height = imageData.height;
        canvas.getContext('2d').putImageData(imageData, 0, 0);
        const div = document.getElementById(`img_div_${image_nr}`);
        div.style.opacity = 1.
    }

    async function run() {
        try {
            document.getElementById('status').innerText = "generating ...";

            if (tokenizer === undefined) {
                tokenizer = await AutoTokenizer.from_pretrained('Xenova/clip-vit-base-patch16', false, false);
                tokenizer.pad_token_id = 0;
            }
            let canvases = [];
            await loading;

            for (let j = 0; j < config.images; j++) {
                const div = document.getElementById(`img_div_${j}`);
                div.style.opacity = 0.5
            }

            const { input_ids } = await tokenizer(text.value, { padding: true, max_length: 77, truncation: true, return_tensor: false });

            // text-encoder
            let start = performance.now();
            const { last_hidden_state } = await models.text_encoder.sess.run({ "input_ids": new ort.Tensor("int32", input_ids, [1, input_ids.length]) });

            let perf_info = [`text_encoder: ${(performance.now() - start).toFixed(1)}ms`];

            for (let j = 0; j < config.images; j++) {
                const latent_shape = [1, 4, 64, 64];
                let latent = new ort.Tensor(randn_latents(latent_shape, sigma), latent_shape);
                const latent_model_input = scale_model_inputs(latent);

                // unet
                start = performance.now();
                let feed = {
                    "sample": latent_model_input,
                    "timestep": new ort.Tensor("int64", [999n], [1]),
                    "encoder_hidden_states": last_hidden_state,
                };
                let { out_sample } = await models.unet.sess.run(feed);
                perf_info.push(`unet: ${(performance.now() - start).toFixed(1)}ms`);

                // scheduler
                new_latents = step(out_sample, latent)

                start = performance.now();

                const { sample } = await models.vae_decoder.sess.run({ "latent_sample": new_latents });
                perf_info.push(`vae_decoder: ${(performance.now() - start).toFixed(1)}ms`);

                draw_image(sample, j);
                log(perf_info.join(", "))
                perf_info = [];
            }
            last_hidden_state.dispose();

            log("done");
        } catch (e) {
            log(e);
        }
    }

    async function hasFp16() {
        try {
            const adapter = await navigator.gpu.requestAdapter()
            return adapter.features.has('shader-f16')
        } catch (e) {
            return false
        }
    }

    function _init_after_dom() {
        hasFp16().then((fp16) => {
            if (fp16) {
                loading = load_models(models);
            } else {
                log("Your GPU or Browser doesn't support webgpu/f16");
            }
        });
    }
    if (document.readyState === 'loading') {
        window.addEventListener('DOMContentLoaded', _init_after_dom);
    } else {
        _init_after_dom();
    }
</script>

</html>